{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# /tl/ Clusters\n",
    "\n",
    "This notebook includes functions that allow us to obtain voicing, rise time, and relative intensity from /tl/ clusters. These functions make use of the [Parselmouth](https://buildmedia.readthedocs.org/media/pdf/parselmouth/latest/parselmouth.pdf) and [audiolabel](https://github.com/rsprouse/audiolabel) packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # For some basic file functionality (creating/removing/parsing file paths)\n",
    "import re  # For regular expessions\n",
    "import numpy as np  # For advanced numerical calculations, multi-dimensional arrays\n",
    "\n",
    "#import audiolabel\n",
    "from audiolabel import read_label  # For reading TextGrid files\n",
    "from phonlab.utils import dir2df  # For finding directories and pulling data\n",
    "import parselmouth  # For incorporating Praat features in this notebook\n",
    "\n",
    "# To get general Praat functionality where native features don't exist\n",
    "from parselmouth.praat import call as pcall\n",
    "\n",
    "import pandas as pd  # For creating managing dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voicing(row, psnd):\n",
    "    '''\n",
    "    Calculates the voice percentage of a portion of an audio file. It's designed to be called from\n",
    "    pd.DataFrame.apply. \n",
    "    \n",
    "    Note that Praat typically takes some time from the beginning of the audio to identify the pitch, \n",
    "    which is needed to get the voicing; thus, we will add some buffer time to our sound called 'pad'.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row: DataFrame row\n",
    "        (Identifies a portion of audio within the time period specified. Each row needs to have a 't1_ph'\n",
    "        and a 'next_ph_t2' attributes, to identify the start and end point of the cluster under evaluation.\n",
    "        A 'sex' ('male' or 'female') attribute is require for each row to set the pitch floor.)\n",
    "    \n",
    "    psnd: Parselmouth Sound\n",
    "        (This is the portion of the audio to be analyzed from 't1_ph' to 'next_ph_t2'.)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    voiced: float\n",
    "        (Percentage of voicing between 't1_ph' and 'next_ph_t2'.)\n",
    "    '''\n",
    "    \n",
    "    pad = 0.5  # Add buffer time needed to identify the pitch\n",
    "    s = psnd.extract_part(row.t1_ph-pad, row.next_ph_t2+pad)  # Select the audio portion of interest\n",
    "    pitch_floor = 100  # Select the default pitch floor (for female speakers)\n",
    "    if row.sex == 'male':  # Change the pitch floor for male speakers\n",
    "        pitch_floor = 70\n",
    "    \n",
    "    # From sound 's', obtain pitch object\n",
    "    pitch = pcall(\n",
    "        s,\n",
    "        'To Pitch (cc)...',\n",
    "        0.001,  # Time step (s) [default = 0.25 sec]\n",
    "        pitch_floor, # Pitch floor (Hz) [default = 75 Hz]\n",
    "        15,  # Max. number of candidates [default]\n",
    "        0,  # Very accurate (unselected) [default = unselected, i.e. off]\n",
    "        0.03,  # Silence threshold [default]\n",
    "        0.45,  # Voicing threashold [default]\n",
    "        0.01,  # Octave cost [default]\n",
    "        0.35,  # Octave-jump cost [default]\n",
    "        0.14,  # Voiced/unvoided cost [default]\n",
    "        250.0,  # Pitch ceiling (Hz) [default = 600 Hz]\n",
    "    )\n",
    "    \n",
    "    # From sound 's' and 'pitch' object, obtain PointProcess object (i.e. 'pulses')\n",
    "    pulses = pcall(\n",
    "        [s, pitch], \n",
    "        'To PointProcess (cc)'\n",
    "    )\n",
    "    \n",
    "    # From sound 's', 'pitch' object, and PointProcess object (i.e. 'pulses'), obtain Voice report (i.e. 'voicing')\n",
    "    voicing = pcall(\n",
    "        [s, pitch, pulses],\n",
    "        'Voice report',\n",
    "        pad,  # Time range (s) (start; add padding)\n",
    "        (row.next_ph_t2-row.t1_ph)+pad,  # Time range (s) (end; add padding)\n",
    "        pitch_floor,  # Pitch floor (Hz) (start)\n",
    "        600.0,  # Pitch floor (Hz) (end)\n",
    "        1.3,  # Maximum period factor [default]\n",
    "        1.6,  # Maximum amplitude factor [default]\n",
    "        0.03,  # Silence threshold [default]\n",
    "        0.45  # Voicing threshold [default]\n",
    "    )\n",
    "    \n",
    "    # From Voice report (i.e. 'voicing'), obtain voicing percentage\n",
    "    m = re.search('unvoiced frames: (?P<percent>\\d+\\.\\d*|\\d+)', voicing)\n",
    "    if m:\n",
    "        voiced = 100.0-float(m.group('percent'))\n",
    "    else:\n",
    "        voiced = np.nan\n",
    "    \n",
    "    return voiced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_intensity(row, psnd):\n",
    "    '''\n",
    "    Calculates the relative intensity (difference) of two segments.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row: DataFrame row\n",
    "        (Identifies a portion of audio within the time periods specified. Each row needs to have a 't1_ph',\n",
    "        't2_ph', and a 'next_ph_t2' attributes, to identify the start and end point of the segments in the\n",
    "        cluster.)\n",
    "    \n",
    "    psnd: Parselmouth Sound\n",
    "       (This is the portion of the audio to be analyzed from 't1_ph' to 'next_ph_t2'.)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rel_intensity: float\n",
    "       (The relative intensity or intensity difference).\n",
    "    '''\n",
    "\n",
    "    t_s = psnd.extract_part(row.t1_ph, row.t2_ph)  # Obtain /t/ segment\n",
    "    l_s = psnd.extract_part(row.t2_ph, row.next_ph_t2)  # Obtain /l/ segment\n",
    "    \n",
    "    return t_s.get_intensity()-l_s.get_intensity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rise_time(row, psnd):\n",
    "    '''\n",
    "    Calculate the rise time in a fricative segment. Rise time is the point in time when a fricative reaches\n",
    "    its highest amplitude. Because rise time is a typically obtained from fricative sounds, we will obtain\n",
    "    this measurement from the lateral segment of the /tl/ cluster, not the stop portion.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row: DataFrame row\n",
    "        (Identifies a portion of audio within the time periods specified. Each row needs to have a 't2_ph' \n",
    "        and a 'next_ph_t2' attributes, to identify the start and end point of the segments in the cluster.)\n",
    "    \n",
    "    psnd: Parselmouth Sound\n",
    "       (This is the portion of the audio to be analyzed from 't2_ph' to 'next_ph_t2'.)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rise_time: float\n",
    "    '''\n",
    "    \n",
    "    s = psnd.extract_part(row.t2_ph, row.next_ph_t2)\n",
    "    rise_time = (pcall(\n",
    "        s, \n",
    "        'Get time of maximum...', \n",
    "        0.0,  # Time range (s) (start) [default] (selects entire sound)\n",
    "        0.0,  # Time range (s) (end) [default] (selects entire sound)\n",
    "        \"Parabolic\"  # Interpolation\n",
    "    )*1000)  # Multiply times 1000 to convert the value (in seconds) to miliseconds\n",
    "    \n",
    "    return rise_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more information on using audiolabel and managing directories, refer to Ronald Sprouse's documentation\n",
    "# on audiolabel (https://github.com/rsprouse/audiolabel)\n",
    "\n",
    "# Identify location of data\n",
    "datadir = './Data'\n",
    "dirpat = '(?P<subject>S\\d+)' # Give each file a subject number, according to file name.\n",
    "\n",
    "# Identify files of interest\n",
    "fdf = dir2df(datadir, dirpat=dirpat, fnpat='\\.wav$', addcols=['barename','dirname'])\n",
    "speaker_sex = './speaker_sex.csv'\n",
    "speaker_sex = pd.read_csv(speaker_sex, encoding = 'utf-8')\n",
    "fdf = fdf.merge(speaker_sex, on='subject', how='left')\n",
    "\n",
    "# Identify data (wav and textgrid files)\n",
    "wav_suffix = '_words.wav'\n",
    "tg_suffix = '_words_Spanish_aligned.TextGrid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_executor(participant):\n",
    "    '''\n",
    "    This function executor applies the functions defined earlier to the data identify in the previous cell.\n",
    "    '''\n",
    "    \n",
    "    print(participant)  # Print participant number to follow progress and isolate potential errors\n",
    "    \n",
    "    wav_file = os.path.join(datadir,participant.relpath,participant.relpath+wav_suffix)\n",
    "    tg_file = os.path.join(datadir,participant.relpath,participant.relpath+tg_suffix)\n",
    "\n",
    "    psnd = parselmouth.Sound(wav_file) \n",
    "\n",
    "    [phdf,wddf] = read_label(tg_file, 'praat')\n",
    "\n",
    "    word_info = './word_info.csv'  #Identify file's location\n",
    "    widf = pd.read_csv(word_info, encoding = 'utf-8')  #Create df for said file using UTF-8\n",
    "    widf.Token = widf.Token.str.upper()  #Make words uppercase to match wdpf\n",
    "\n",
    "    merged_wddf = wddf.merge(widf, left_on='label', right_on='Token', how='left').sort_values(by='t1')\n",
    "\n",
    "    phdf = phdf.assign(  # Create new column\n",
    "        next_ph=phdf.label.shift(periods=-1,axis=0,fill_value=''),  #Roll phone's label to create cluster\n",
    "        next_ph_t2=phdf.t2.shift(periods=-1,axis=0,fill_value=np.nan))  # Roll phone's t2 \n",
    "\n",
    "    phdf_tl = phdf[(phdf.label=='t')&(phdf.next_ph=='l')]\n",
    "\n",
    "    phwddf = pd.merge_asof(\n",
    "        phdf_tl.rename(\n",
    "            columns={'t1':'t1_ph'}), \n",
    "        merged_wddf.rename(\n",
    "            columns={'t1':'t1_wd'}), \n",
    "        left_on='t1_ph', \n",
    "        right_on='t1_wd', \n",
    "        suffixes=['_ph', '_wd']\n",
    "    )\n",
    "\n",
    "    phwddf = phwddf.assign(\n",
    "        sex=participant.sex\n",
    "    )\n",
    "\n",
    "    phwddf = phwddf.assign(\n",
    "        voicing=phwddf.apply(\n",
    "            get_voicing,\n",
    "            args=([psnd]), \n",
    "            axis=1\n",
    "        ),\n",
    "        rel_intensity=phwddf.apply(\n",
    "            get_relative_intensity,\n",
    "            args=([psnd]),\n",
    "            axis=1\n",
    "        ),\n",
    "        rise_time=phwddf.apply(\n",
    "            get_rise_time, \n",
    "            args=([psnd]), \n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    return phwddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all measurements\n",
    "\n",
    "measurements_df = pd.concat(fdf.apply(func_executor, axis=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify any empty cells or cells with NaN -- an empty df means there were no issues\n",
    "\n",
    "measurements_df[np.any(measurements_df.isna(), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe measurement results as 'tl.csv' under a folder called 'Results'\n",
    "\n",
    "export_csv = new_df.to_csv('Results/tl.csv', index=None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
